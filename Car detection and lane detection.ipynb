{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "#import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "import zipfile\n",
    "import pathlib\n",
    "import os\n",
    "\n",
    "from distutils.version import StrictVersion\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# This is needed since the notebook is stored in the object_detection folder.\n",
    "sys.path.append(\"..\")\n",
    "from object_detection.utils import ops as utils_ops\n",
    "\n",
    "if StrictVersion(tf.__version__) < StrictVersion('1.9.0'):\n",
    "    raise ImportError('Please upgrade your TensorFlow installation to v1.9.* or later!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import label_map_util\n",
    "\n",
    "from utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run this to avoid downloading every time the model\n",
    "MODEL_NAME = 'ssd_mobilenet_v1_coco_2017_11_17'\n",
    "PATH_TO_FROZEN_GRAPH = MODEL_NAME + '/frozen_inference_graph.pb'\n",
    "PATH_TO_LABELS = 'data/mscoco_label_map.pbtxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--EVEN IF THE MODEL IS NOT DOWNLOADED, THIS CODE BOX MUST STILL BE RUN----\n",
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.io.gfile.GFile(PATH_TO_FROZEN_GRAPH, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the error \"tensorflow does not have module gfile\" was solved by replacing everywhere with tf.io.gfile.GFile()\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference_for_single_image(image, graph):\n",
    "    if 'detection_masks' in tensor_dict:\n",
    "        # The following processing is only for single image\n",
    "        detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n",
    "        detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n",
    "        # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
    "        real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n",
    "        detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n",
    "        detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n",
    "        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
    "            detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
    "        detection_masks_reframed = tf.cast(\n",
    "            tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
    "        # Follow the convention by adding back the batch dimension\n",
    "        tensor_dict['detection_masks'] = tf.expand_dims(\n",
    "            detection_masks_reframed, 0)\n",
    "    image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
    "\n",
    "    # Run inference\n",
    "    output_dict = sess.run(tensor_dict,\n",
    "                            feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
    "\n",
    "    # all outputs are float32 numpy arrays, so convert types as appropriate\n",
    "    output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
    "    output_dict['detection_classes'] = output_dict[\n",
    "        'detection_classes'][0].astype(np.uint8)\n",
    "    output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
    "    output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
    "    if 'detection_masks' in output_dict:\n",
    "        output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing thr functions for lane detection\n",
    "#loading the image\n",
    "def process_image(image):\n",
    "\theight = image.shape[0]\n",
    "\twidth = image.shape[1]\n",
    "\n",
    "\n",
    "\t#defining the region of interest\n",
    "\tregion_of_interest = [\n",
    "\t\t(0, 290),\n",
    "\t\t(330, 210), \n",
    "\t\t(550, height)\n",
    "\t]\t\n",
    "\n",
    "\tgray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\tcanny_image = cv2.Canny(image, 100, 200)\n",
    "\n",
    "\t#crop the image leaving only the region of interest\n",
    "\tcropped_image = region_of_interest_mask(canny_image, np.array([region_of_interest], np.int32))\n",
    "\n",
    "\t#now we have to draw the lines\n",
    "\tlines = cv2.HoughLinesP(cropped_image, rho = 6, \n",
    "\t\ttheta = np.pi/60, threshold = 170, lines = np.array([]), \n",
    "\t\tminLineLength = 40, maxLineGap = 25)\n",
    "\n",
    "\timage_with_lines = draw_the_lines(image, lines)\n",
    "\treturn image_with_lines\n",
    "\n",
    "\n",
    "#now i want to cover all areas in the image that are not the region of interest\n",
    "def region_of_interest_mask(img, vertices):\n",
    "\tmask = np.zeros_like(img)\n",
    "\t#channel_count = img.shape[2]\n",
    "\tmatch_mask_color = 255\n",
    "\tcv2.fillPoly(mask, vertices, match_mask_color)\n",
    "\tmasked_image = cv2.bitwise_and(img, mask)\n",
    "\treturn masked_image\n",
    "\n",
    "#function to draw the lines on the image\n",
    "def draw_the_lines(img, lines):\n",
    "\timg_copy = np.copy(img)\n",
    "\tblank_image = np.zeros((img.shape[0], img.shape[1], 3), dtype = np.uint8)\n",
    "\tfor line in lines:\n",
    "\t\tfor x1, y1, x2, y2 in line:\n",
    "\t\t\tcv2.line(blank_image, (x1, y1), (x2, y2), (0, 255, 0), thickness = 1)\n",
    "\t#now i merge the two images\n",
    "\timg = cv2.addWeighted(img, 0.8, blank_image, 1, 0.0)\n",
    "\treturn img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cap = cv2.VideoCapture('/Users/pietromanfredi/Desktop/lane_detection/car_on_road.mp4')\n",
    "try:\n",
    "    with detection_graph.as_default():\n",
    "        with tf.Session() as sess:\n",
    "                # Get handles to input and output tensors\n",
    "                ops = tf.get_default_graph().get_operations()\n",
    "                all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
    "                tensor_dict = {}\n",
    "                for key in [\n",
    "                  'num_detections', 'detection_boxes', 'detection_scores',\n",
    "                  'detection_classes', 'detection_masks'\n",
    "                ]:\n",
    "                    tensor_name = key + ':0'\n",
    "                    if tensor_name in all_tensor_names:\n",
    "                        tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
    "                      tensor_name)\n",
    "\n",
    "                while True:\n",
    "                    ret, image_np = cap.read()\n",
    "                    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "                    image_np_expanded = np.expand_dims(image_np, axis=0) #this code is totally useless\n",
    "                    b = cv2.resize(image_np,(660,330),fx=0,fy=0, interpolation = cv2.INTER_CUBIC) #it is important to resize\n",
    "                    # Actual detection.\n",
    "                    output_dict = run_inference_for_single_image(b, detection_graph)\n",
    "                    # Visualization of the results of a detection.\n",
    "                    vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "                        b,\n",
    "                        output_dict['detection_boxes'],\n",
    "                        output_dict['detection_classes'],\n",
    "                        output_dict['detection_scores'],\n",
    "                        category_index,\n",
    "                        instance_masks=output_dict.get('detection_masks'),\n",
    "                        use_normalized_coordinates=True,\n",
    "                        line_thickness=8)\n",
    "                    b = process_image(b) #this is the part that does lane detection\n",
    "                    cv2.imshow('Object detection',b)\n",
    "                    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                        cap.release()\n",
    "                        cv2.destroyAllWindows()\n",
    "                        break\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
